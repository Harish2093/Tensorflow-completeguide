{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow-distributed.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRlp5Abizm44",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dae849e1-859e-4d71-8b88-f01225317b6e"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHRe5EdLzx0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import numpy as np"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbffJwPZ0Kmu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e5092c8e-fbe2-4a49-8adb-ab587a09e46a"
      },
      "source": [
        "(x_train,y_train),(x_test,y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpMkXLAD0XAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train/255. \n",
        "x_test = x_test/255."
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN2eOOAn0j1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(-1,28*28)\n",
        "x_test = x_test.reshape(-1,28*28)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48d3PT330_qA",
        "colab_type": "text"
      },
      "source": [
        "#Define non distributed model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6rG0HRQ0zdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_normal = tf.keras.models.Sequential()\n",
        "model_normal.add(tf.keras.layers.Dense(units=128,activation='relu',input_shape=(28*28,)))\n",
        "model_normal.add(tf.keras.layers.Dropout(rate=0.2))\n",
        "model_normal.add(tf.keras.layers.Dense(units=10,activation='softmax'))\n",
        "model_normal.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['sparse_categorical_accuracy'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pL11kBrH2deX",
        "colab_type": "text"
      },
      "source": [
        "#Distributed Strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd_jtuQs2lbt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52d462e0-d735-45ff-c872-430e364d5df8"
      },
      "source": [
        "distribute = tf.distribute.MirroredStrategy()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkxlNsN22zeX",
        "colab_type": "text"
      },
      "source": [
        "# Distributed model defination"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIzfkjyE23Lc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with distribute.scope():\n",
        "  model_distributed = tf.keras.models.Sequential()\n",
        "  model_distributed.add(tf.keras.layers.Dense(units=128,activation='relu',input_shape=(28*28,)))\n",
        "  model_distributed.add(tf.keras.layers.Dropout(rate=0.2))\n",
        "  model_distributed.add(tf.keras.layers.Dense(units=10,activation='softmax'))\n",
        "  model_distributed.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['sparse_categorical_accuracy'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL9CcU118HZl",
        "colab_type": "text"
      },
      "source": [
        "#Comparison of both"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPFgg1g43IOx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d33ed627-8984-42a9-e124-7f9c32a20c24"
      },
      "source": [
        "start_time = time.time()\n",
        "model_normal.fit(x_train,y_train,epochs=5,batch_size=32)\n",
        "print(\"Normal model took {} seconds of time\".format(time.time()-start_time))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2942 - sparse_categorical_accuracy: 0.9158\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1465 - sparse_categorical_accuracy: 0.9567\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1070 - sparse_categorical_accuracy: 0.9675\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0880 - sparse_categorical_accuracy: 0.9730\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0763 - sparse_categorical_accuracy: 0.9758\n",
            "Normal model took 20.169447660446167 seconds of time\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu7DNG_64yq6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "1afa92ba-e3f5-409e-d2e0-00345d41403f"
      },
      "source": [
        "start_time = time.time()\n",
        "model_distributed.fit(x_train,y_train,epochs=5,batch_size=32)\n",
        "print(\"Distributed model took {} seconds of time\".format(time.time()-start_time))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2899 - sparse_categorical_accuracy: 0.9152\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1413 - sparse_categorical_accuracy: 0.9581\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1054 - sparse_categorical_accuracy: 0.9681\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0874 - sparse_categorical_accuracy: 0.9732\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0731 - sparse_categorical_accuracy: 0.9773\n",
            "Distributed model took 24.904118299484253 seconds of time\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6EkBLj-7TUe",
        "colab_type": "text"
      },
      "source": [
        "Due to the combination of CPU and GPU we see the above results, as CPU worsen the performance of the GPU. But if you have two or more GPU's you can watch the distributed model works better"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WReoZ7Ly4-yV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}